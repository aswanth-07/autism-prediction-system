{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'Frequency': pd.read_csv('Data/Processed Data/frequency_encoded_data.csv'),\n",
    "    'One-Hot': pd.read_csv('Data/Processed Data/one_hot_encoded_data.csv'),\n",
    "    'Target': pd.read_csv('Data/Processed Data/target_encoded_data.csv')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Param-grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'scale_pos_weight': [1, 3, 6, 9, 12, 15],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [50,100, 200]\n",
    "}\n",
    "\n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'n_estimators': [50,100, 200]\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'class_weight': [{0:1, 1:w} for w in [1, 3, 6, 9, 12, 15]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_models(X_train, X_test, y_train, y_test, use_smote=False):\n",
    "    if use_smote:\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    models = {\n",
    "        'XGBoost': (xgb.XGBClassifier(random_state=42), xgb_params),\n",
    "        'AdaBoost': (AdaBoostClassifier(algorithm='SAMME',random_state=42), ada_params),\n",
    "        'SVM': (SVC(kernel='linear',probability=True, random_state=42), svm_params)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for name, (model, params) in models.items():\n",
    "        grid = GridSearchCV(model, params, scoring='f1', cv=5)\n",
    "        grid.fit(X_train, y_train)\n",
    "        y_pred = grid.predict(X_test)\n",
    "        results[name] = {\n",
    "            'best_params': grid.best_params_,\n",
    "            'best_score': grid.best_score_,\n",
    "            'test_f1': f1_score(y_test, y_pred)\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Frequency encoding without SMOTE:\n",
      "\n",
      "XGBoost:\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'scale_pos_weight': 3}\n",
      "CV F1-Score: 0.6824\n",
      "Test F1-Score: 0.6842\n",
      "\n",
      "AdaBoost:\n",
      "Best Parameters: {'learning_rate': 1.0, 'n_estimators': 100}\n",
      "CV F1-Score: 0.6457\n",
      "Test F1-Score: 0.6667\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 0.1, 'class_weight': {0: 1, 1: 3}, 'gamma': 0.001}\n",
      "CV F1-Score: 0.6540\n",
      "Test F1-Score: 0.7059\n",
      "\n",
      "Results for Frequency encoding with SMOTE:\n",
      "\n",
      "XGBoost:\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'scale_pos_weight': 6}\n",
      "CV F1-Score: 0.9002\n",
      "Test F1-Score: 0.6234\n",
      "\n",
      "AdaBoost:\n",
      "Best Parameters: {'learning_rate': 1.0, 'n_estimators': 50}\n",
      "CV F1-Score: 0.8638\n",
      "Test F1-Score: 0.7059\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 10, 'class_weight': {0: 1, 1: 3}, 'gamma': 0.001}\n",
      "CV F1-Score: 0.8546\n",
      "Test F1-Score: 0.6286\n",
      "\n",
      "Results for One-Hot encoding without SMOTE:\n",
      "\n",
      "XGBoost:\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'scale_pos_weight': 3}\n",
      "CV F1-Score: 0.6964\n",
      "Test F1-Score: 0.7273\n",
      "\n",
      "AdaBoost:\n",
      "Best Parameters: {'learning_rate': 1.0, 'n_estimators': 100}\n",
      "CV F1-Score: 0.6522\n",
      "Test F1-Score: 0.6364\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 0.1, 'class_weight': {0: 1, 1: 6}, 'gamma': 0.001}\n",
      "CV F1-Score: 0.6475\n",
      "Test F1-Score: 0.6966\n",
      "\n",
      "Results for One-Hot encoding with SMOTE:\n",
      "\n",
      "XGBoost:\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'scale_pos_weight': 6}\n",
      "CV F1-Score: 0.9015\n",
      "Test F1-Score: 0.6437\n",
      "\n",
      "AdaBoost:\n",
      "Best Parameters: {'learning_rate': 0.01, 'n_estimators': 200}\n",
      "CV F1-Score: 0.8788\n",
      "Test F1-Score: 0.6200\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 0.1, 'class_weight': {0: 1, 1: 1}, 'gamma': 0.001}\n",
      "CV F1-Score: 0.8741\n",
      "Test F1-Score: 0.6329\n",
      "\n",
      "Results for Target encoding without SMOTE:\n",
      "\n",
      "XGBoost:\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'scale_pos_weight': 3}\n",
      "CV F1-Score: 0.6785\n",
      "Test F1-Score: 0.6829\n",
      "\n",
      "AdaBoost:\n",
      "Best Parameters: {'learning_rate': 1.0, 'n_estimators': 50}\n",
      "CV F1-Score: 0.6547\n",
      "Test F1-Score: 0.6471\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 1, 'class_weight': {0: 1, 1: 1}, 'gamma': 0.001}\n",
      "CV F1-Score: 0.6670\n",
      "Test F1-Score: 0.7429\n",
      "\n",
      "Results for Target encoding with SMOTE:\n",
      "\n",
      "XGBoost:\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'scale_pos_weight': 1}\n",
      "CV F1-Score: 0.9088\n",
      "Test F1-Score: 0.6667\n",
      "\n",
      "AdaBoost:\n",
      "Best Parameters: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "CV F1-Score: 0.8716\n",
      "Test F1-Score: 0.6667\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'C': 1, 'class_weight': {0: 1, 1: 3}, 'gamma': 0.001}\n",
      "CV F1-Score: 0.8667\n",
      "Test F1-Score: 0.6538\n",
      "\n",
      "Best Overall Model:\n",
      "Model: SVM\n",
      "Encoding: Target\n",
      "SMOTE: False\n",
      "F1-Score: 0.7429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Models/best_model.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store best models and scores\n",
    "best_overall = {\n",
    "    'score': 0,\n",
    "    'model': None,\n",
    "    'params': None,\n",
    "    'encoding': None,\n",
    "    'smote': None\n",
    "}\n",
    "\n",
    "# Evaluate all combinations\n",
    "for enc_name, data in datasets.items():\n",
    "    X = data.drop('Class/ASD', axis=1)\n",
    "    y = data['Class/ASD']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for smote in [False, True]:\n",
    "        results = tune_models(X_train, X_test, y_train, y_test, smote)\n",
    "        \n",
    "        print(f\"\\nResults for {enc_name} encoding {'with' if smote else 'without'} SMOTE:\")\n",
    "        for model_name, result in results.items():\n",
    "            print(f\"\\n{model_name}:\")\n",
    "            print(f\"Best Parameters: {result['best_params']}\")\n",
    "            print(f\"CV F1-Score: {result['best_score']:.4f}\")\n",
    "            print(f\"Test F1-Score: {result['test_f1']:.4f}\")\n",
    "            \n",
    "            # Update best overall model\n",
    "            if result['test_f1'] > best_overall['score']:\n",
    "                best_overall.update({\n",
    "                    'score': result['test_f1'],\n",
    "                    'model': model_name,\n",
    "                    'params': result['best_params'],\n",
    "                    'encoding': enc_name,\n",
    "                    'smote': smote\n",
    "                })\n",
    "\n",
    "# Save best model\n",
    "print(\"\\nBest Overall Model:\")\n",
    "print(f\"Model: {best_overall['model']}\")\n",
    "print(f\"Encoding: {best_overall['encoding']}\")\n",
    "print(f\"SMOTE: {best_overall['smote']}\")\n",
    "print(f\"F1-Score: {best_overall['score']:.4f}\")\n",
    "\n",
    "os.makedirs('Models', exist_ok=True)\n",
    "\n",
    "# Train and save the best model\n",
    "X = datasets[best_overall['encoding']].drop('Class/ASD', axis=1)\n",
    "y = datasets[best_overall['encoding']]['Class/ASD']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "if best_overall['model'] == 'XGBoost':\n",
    "    best_model = xgb.XGBClassifier(random_state=42, **best_overall['params'])\n",
    "elif best_overall['model'] == 'AdaBoost':\n",
    "    best_model = AdaBoostClassifier(algorithm='SAMME',random_state=42, **best_overall['params'])\n",
    "else:\n",
    "    best_model = SVC(kernel='linear',probability=True, random_state=42, **best_overall['params'])\n",
    "\n",
    "if best_overall['smote']:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Save model and configuration\n",
    "model_info = {\n",
    "    'model': best_model,\n",
    "    'encoding': best_overall['encoding'],\n",
    "    'smote': best_overall['smote'],\n",
    "    'params': best_overall['params']\n",
    "}\n",
    "joblib.dump(model_info, 'Models/best_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
